{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dylanbforde/ai-medical-image-analysis/blob/main/MRNet_tutorial_solution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJcreEvoLAMR"
      },
      "source": [
        "**TO DO:** Make a copy of this notebook in your own Google drive and edit the copy.\n",
        "\n",
        "**TO DO:** Download the data at the following link https://stanfordmlgroup.github.io/competitions/mrnet/ and upload it to your Google Drive.\n",
        "\n",
        "This will download a folder named 'data'.\n",
        "\n",
        "*   The dataset consists of 1,250 knee MRIs with image level labels.\n",
        "*   The training data consists of 1,130 MRIs and the validation data consists of 120 MRIs.\n",
        "*   They are labelled as abnormal, having an acl tear and/or meniscus tear.\n",
        "*   Each MRI exam includes data from the axial, coronal and sagittal plane.\n",
        "*   Axial is a Proton-Density series, coronal is a T1-weighted series and sagittal is T2-weighted series.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gAGkxwk-cRff"
      },
      "source": [
        "Go to \"Edit\" on the toolbar, then \"Notebook Settings\" and change the hardware accelerator to GPU.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U1WXxXUT_6_a"
      },
      "source": [
        "#Mount Google Drive to access your data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gOOfjmRD_ppM",
        "outputId": "b89fe8e6-5b31-4b5b-d91f-13e6ff4ea6b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1jByfpneRc97"
      },
      "source": [
        "The following code uses a python library named 'torchsample'. This is not installed in Google Colab. We can import it by running the commands in the following cell. The exclamation mark communicates to Google Colab to run the commands in the terminal rather than in Python in the current notebook.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FIbY0gCaRvMU",
        "outputId": "28f315ed-812e-422b-9283-b0b56150b41b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchsample\n",
            "  Downloading torchsample-0.1.0.tar.gz (393 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/393.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m174.1/393.6 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m393.6/393.6 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from torchsample) (2.6.0+cpu)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->torchsample) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->torchsample) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->torchsample) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->torchsample) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->torchsample) (2025.5.1)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->torchsample) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.9.0->torchsample) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.9.0->torchsample) (3.0.2)\n",
            "Building wheels for collected packages: torchsample\n",
            "  Building wheel for torchsample (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torchsample: filename=torchsample-0.1.0-py3-none-any.whl size=16698 sha256=721547ae177a1b6b82366f2a6f606e4739071ec41b641ff2953153d69becef69\n",
            "  Stored in directory: /root/.cache/pip/wheels/c6/c8/b6/19457b219a37c931e360e7bce0e014e92422de1f6257d1a49d\n",
            "Successfully built torchsample\n",
            "Installing collected packages: torchsample\n",
            "Successfully installed torchsample-0.1.0\n",
            "Collecting visdom\n",
            "  Downloading visdom-0.2.4.tar.gz (1.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.8 in /usr/local/lib/python3.11/dist-packages (from visdom) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from visdom) (1.15.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from visdom) (2.32.3)\n",
            "Requirement already satisfied: tornado in /usr/local/lib/python3.11/dist-packages (from visdom) (6.4.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from visdom) (1.17.0)\n",
            "Collecting jsonpatch (from visdom)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.11/dist-packages (from visdom) (1.8.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from visdom) (3.5)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from visdom) (11.2.1)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch->visdom)\n",
            "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->visdom) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->visdom) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->visdom) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->visdom) (2025.6.15)\n",
            "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Downloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
            "Building wheels for collected packages: visdom\n",
            "  Building wheel for visdom (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for visdom: filename=visdom-0.2.4-py3-none-any.whl size=1408288 sha256=73e4e8d7736a34e7946b5129a69e06cebd61ee747d3e55f83b2698bf6461e124\n",
            "  Stored in directory: /root/.cache/pip/wheels/fa/a4/bb/2be445c295d88a74f9c0a4232f04860ca489a5c7c57eb959d9\n",
            "Successfully built visdom\n",
            "Installing collected packages: jsonpointer, jsonpatch, visdom\n",
            "Successfully installed jsonpatch-1.33 jsonpointer-3.0.0 visdom-0.2.4\n",
            "Collecting nibabel\n",
            "  Downloading nibabel-5.3.2-py3-none-any.whl.metadata (9.1 kB)\n",
            "Requirement already satisfied: importlib-resources>=5.12 in /usr/local/lib/python3.11/dist-packages (from nibabel) (6.5.2)\n",
            "Requirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.11/dist-packages (from nibabel) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20 in /usr/local/lib/python3.11/dist-packages (from nibabel) (25.0)\n",
            "Requirement already satisfied: typing-extensions>=4.6 in /usr/local/lib/python3.11/dist-packages (from nibabel) (4.14.0)\n",
            "Downloading nibabel-5.3.2-py3-none-any.whl (3.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nibabel\n",
            "Successfully installed nibabel-5.3.2\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (3.14.0)\n",
            "Requirement already satisfied: numpy>=1.19.3 in /usr/local/lib/python3.11/dist-packages (from h5py) (2.0.2)\n",
            "Collecting tensorboardX\n",
            "  Downloading tensorboardx-2.6.4-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from tensorboardX) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorboardX) (25.0)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.11/dist-packages (from tensorboardX) (5.29.5)\n",
            "Downloading tensorboardx-2.6.4-py3-none-any.whl (87 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tensorboardX\n",
            "Successfully installed tensorboardX-2.6.4\n"
          ]
        }
      ],
      "source": [
        "!pip install torchsample\n",
        "!pip install visdom\n",
        "!pip install nibabel\n",
        "!pip install h5py\n",
        "!pip install tensorboardX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "XoOPghzXShT1"
      },
      "outputs": [],
      "source": [
        "#import all libraries\n",
        "import torch.optim as optim\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models\n",
        "import numpy as np\n",
        "import os\n",
        "import sys\n",
        "import pickle\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data as data\n",
        "import pandas as pd\n",
        "from torch.autograd import Variable\n",
        "from torchvision import transforms\n",
        "from tensorboardX import SummaryWriter\n",
        "import math\n",
        "from sklearn import metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DiUxtO2XCqI-"
      },
      "source": [
        "#Define your model\n",
        "The model is defined in the class 'Net'. The 'init' function initialises the architecture of the model.\n",
        "\n",
        "The line of code; ```self.pretrained_model = models.resnet18(pretrained=True)``` initialises a pre-trained ResNet18, pre-trained on the ImageNet Dataset. This initialises the weights of the model with the weights for a ResNet18 model that was trained on the ImageNet dataset. This speeds up training.\n",
        "\n",
        "The line of code ```self.classifer = nn.Linear(1000, 1)``` is a fully connected layer that makes the final prediction.\n",
        "\n",
        "After the model is initialised, the forward function is called iteratively throughout the training process. The output size of each line is shown in the code.\n",
        "\n",
        "More information con defining models can be found at https://pytorch.org/vision/stable/models.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V7yqBURoddk4",
        "outputId": "55744c6e-89fe-47ec-af8d-0dbe0e157183"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 174MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "models.resnet18(pretrained=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dghoOuiqe61j",
        "outputId": "145b5a93-6136-4652-f1f8-537a2734eaa5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False),\n",
              " BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
              " ReLU(inplace=True),\n",
              " MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False),\n",
              " Sequential(\n",
              "   (0): BasicBlock(\n",
              "     (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "     (relu): ReLU(inplace=True)\n",
              "     (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "     (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "   )\n",
              "   (1): BasicBlock(\n",
              "     (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "     (relu): ReLU(inplace=True)\n",
              "     (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "     (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "   )\n",
              " ),\n",
              " Sequential(\n",
              "   (0): BasicBlock(\n",
              "     (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "     (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "     (relu): ReLU(inplace=True)\n",
              "     (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "     (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "     (downsample): Sequential(\n",
              "       (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "       (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "     )\n",
              "   )\n",
              "   (1): BasicBlock(\n",
              "     (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "     (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "     (relu): ReLU(inplace=True)\n",
              "     (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "     (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "   )\n",
              " ),\n",
              " Sequential(\n",
              "   (0): BasicBlock(\n",
              "     (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "     (relu): ReLU(inplace=True)\n",
              "     (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "     (downsample): Sequential(\n",
              "       (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "       (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "     )\n",
              "   )\n",
              "   (1): BasicBlock(\n",
              "     (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "     (relu): ReLU(inplace=True)\n",
              "     (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "   )\n",
              " ),\n",
              " Sequential(\n",
              "   (0): BasicBlock(\n",
              "     (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "     (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "     (relu): ReLU(inplace=True)\n",
              "     (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "     (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "     (downsample): Sequential(\n",
              "       (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "       (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "     )\n",
              "   )\n",
              "   (1): BasicBlock(\n",
              "     (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "     (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "     (relu): ReLU(inplace=True)\n",
              "     (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "     (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "   )\n",
              " ),\n",
              " AdaptiveAvgPool2d(output_size=(1, 1))]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "list( models.resnet18(pretrained=True).children())[:-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "VRAEyCaIApjx"
      },
      "outputs": [],
      "source": [
        "#modify the last fully connected layer to output (1) instead of (1000)\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.pretrained_model =  nn.Sequential(*list(models.resnet18(pretrained=True).children())[:-1]  )    # delete the last fc layer.\n",
        "        self.classifer = nn.Linear(512, 1)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        # input size of x (1, s, 3, 256, 256) where s is the number of slices in one MRI\n",
        "        x = torch.squeeze(x, dim=0) #output size (s, 3, 256, 256)\n",
        "        x = self.pretrained_model(x) #output size (s, 512)\n",
        "        output = torch.max(x, 0, keepdim=True)[0] #output size (1, 512)\n",
        "        output = self.classifer(output.squeeze(2).squeeze(2)) #output size (1)\n",
        "\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "R-hXicsXnbBI"
      },
      "outputs": [],
      "source": [
        "#add another fully connected layer to convert output (1,1000) to (1)\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.pretrained_model =  models.resnet18(pretrained=True)   # delete the last fc layer.\n",
        "        self.classifer = nn.Linear(1000, 1)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        # input size of x (batch_size, s, 3, 256, 256) where s is the number of slices in one MRI\n",
        "        batch_size, num_slices, channels, height, width = x.size()\n",
        "        # Reshape the input to process slices individually\n",
        "        x = x.view(-1, channels, height, width) # output size (batch_size * num_slices, 3, 256, 256)\n",
        "\n",
        "        x = self.pretrained_model(x) # output size (batch_size * num_slices, 1000)\n",
        "        x = x.view(batch_size, num_slices, -1) # output size (batch_size, num_slices, 1000)\n",
        "\n",
        "        output = torch.max(x, 1, keepdim=True)[0] # output size (batch_size, 1, 1000)\n",
        "        output =nn.ReLU()(output)\n",
        "        output = self.classifer(output.squeeze(1)) # output size (batch_size, 1)\n",
        "\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2w3Sd-fon4qr",
        "outputId": "972e9982-7c32-4638-da43-03fbba31a812"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Net(\n",
              "  (pretrained_model): ResNet(\n",
              "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "    (layer1): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (layer2): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (layer3): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (layer4): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "    (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
              "  )\n",
              "  (classifer): Linear(in_features=1000, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "mod=Net()\n",
        "mod"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QNFlV3zwZHyq"
      },
      "source": [
        "TO NOTE:\n",
        "Models defined in Pytorch expect 2D image data in the dimensions (batch size, channels (colours), height of the image, width of the image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wOLCnvQ4HUd2"
      },
      "source": [
        "#Create Dataloader\n",
        "The 'init' function initialises the dataloader. This class is responsible for loading the datasets. It takes the 'root_dir', 'task', 'plane', 'train' and 'transform' as input parameters.\n",
        "root_dir - the directory to where the data is stored.\n",
        "\n",
        "task - whether the model is being trained to detect acl tears, meniscus tears or abnormalities. Possible values are 'acl', 'meniscus' or 'abnormal'.\n",
        "\n",
        "plane - whether the model is being trained on axial, coronal or sagittal data. Possible values are 'axial', 'coronal' or 'sagittal'.\n",
        "\n",
        "train - is this the dataloader for the training data or the validation data. Possible values are 'True' to load training data or 'False' to load validation data.\n",
        "\n",
        "transform - a compose function for performing transformations to the images.\n",
        "\n",
        "The init function creates 1) a list of paths to each MRI, 2) a corresponding list of labels that are either ones or zeros and 3) weights.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "The __len__ function returns the length of the dataset.\n",
        "\n",
        "\n",
        "---\n",
        "The __getitem__ function is iteratively called throughout the training process. It takes an index as a input parameter. It loads the MRI at the given index from the list of paths defined in the init function. It also returns the label and weight for the MRI at that index.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "AQzFc45wHOwX"
      },
      "outputs": [],
      "source": [
        "class Dataset(data.Dataset):\n",
        "    def __init__(self, root_dir, task, plane, train=False, transform=None):\n",
        "        super().__init__()\n",
        "        self.task = task\n",
        "        self.plane = plane\n",
        "        self.root_dir = root_dir\n",
        "        self.train=train\n",
        "        if self.train == True:\n",
        "            self.folder_path = self.root_dir + 'train/{0}/'.format(plane)\n",
        "            self.records = pd.read_csv(\n",
        "                self.root_dir + 'train-{0}.csv'.format(task), header=None, names=['id', 'label'])\n",
        "        else:\n",
        "            self.folder_path = self.root_dir + 'valid/{0}/'.format(plane)\n",
        "\n",
        "            self.records = pd.read_csv(\n",
        "                self.root_dir + 'valid-{0}.csv'.format(task), header=None, names=['id', 'label'])\n",
        "\n",
        "        self.records['id'] = self.records['id'].map(\n",
        "            lambda i: '0' * (4 - len(str(i))) + str(i))\n",
        "        self.paths = [self.folder_path + filename +\n",
        "                      '.npy' for filename in self.records['id'].tolist()]\n",
        "        self.labels = self.records['label'].tolist()\n",
        "\n",
        "        self.transform = transform\n",
        "\n",
        "        pos = np.sum(self.labels)\n",
        "        neg = len(self.labels) - pos\n",
        "        self.weights = [1, neg / pos]\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.paths)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        array = np.load(self.paths[index])\n",
        "\n",
        "        label = self.labels[index]\n",
        "        label = torch.FloatTensor([label])\n",
        "\n",
        "        if self.transform:\n",
        "          transformed_slices = []\n",
        "          for i in array:\n",
        "            transformed_slice = self.transform(i)\n",
        "            transformed_slice = transformed_slice.repeat(3, 1, 1)\n",
        "            transformed_slices.append(transformed_slice)\n",
        "          array = torch.stack(transformed_slices)\n",
        "        else:\n",
        "          array = torch.from_numpy(array).float()\n",
        "          array = array.unsqueeze(1)\n",
        "          array = array.repeat(1, 3, 1, 1)\n",
        "\n",
        "        array = array.float()\n",
        "\n",
        "        if label.item() == 1:\n",
        "            weight = np.array([self.weights[1]])\n",
        "            weight = torch.FloatTensor(weight)\n",
        "        else:\n",
        "            weight = np.array([self.weights[0]])\n",
        "            weight = torch.FloatTensor(weight)\n",
        "\n",
        "        if array.shape[0] < 32:\n",
        "            zeros = torch.zeros((32 - array.shape[0], 3, 256, 256))\n",
        "            array = torch.cat((array, zeros), 0)\n",
        "\n",
        "        elif array.shape[0] > 32:\n",
        "            array = array[:32, :, :, :]\n",
        "\n",
        "        return array, label, weight"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wr_G0QuVedGz"
      },
      "source": [
        "#Train the model\n",
        "##Define variables\n",
        "**TO DO:** Change directory to where you store your data. Use the toolbar to the side of this page to view your file system."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "hhB7KNW84hCk"
      },
      "outputs": [],
      "source": [
        "directory = \"/content/drive/Shared drives/MRNet Group Assignment/MRI Data/\"\n",
        "task = 'acl'\n",
        "plane = 'sagittal'\n",
        "lr = 1e-5 #learning rate\n",
        "num_epochs = 50 # number of epochs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lZgqHPAEoxv2"
      },
      "source": [
        "##Initialise the model, optimiser, scheduler, transformations and data loader."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZOsUXMCT4Y56",
        "outputId": "1b571a8b-4a2c-4f31-9e22-8b6ee072bdc2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "\n",
        "model = Net() #initialise the model\n",
        "if torch.cuda.is_available(): #if there is a GPU available, put the model on the GPU\n",
        "    model = model.cuda()\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr= lr, weight_decay=0.1) #define the optimiser as Adam\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "        optimizer, patience=4, factor=.3, threshold=1e-4, verbose=True) #define a scheduler that decreases the learning rate if there has been no reduction in validation loss is four epochs\n",
        "\n",
        "#define a compose function that is a series of transformations on the images.\n",
        "augmentor = transforms.Compose([\n",
        "    # 1. numpy / PIL  ➜  float32 tensor in [0, 1]\n",
        "    transforms.ToTensor(),\n",
        "\n",
        "    # 2. ± 25° random rotation (keeps image size)\n",
        "    transforms.RandomRotation(25),\n",
        "\n",
        "    # 3. Random translation: up to 11 % of width & height\n",
        "    transforms.RandomAffine(\n",
        "        degrees=0,                 # no extra rotation here\n",
        "        translate=(0.11, 0.11)\n",
        "    ),\n",
        "\n",
        "    # 4. Random left-right flip\n",
        "    transforms.RandomHorizontalFlip()\n",
        "])\n",
        "\n",
        "#initialise the train and validation datasets (class we defined earlier) and then initialise a Pytorch's dataloader\n",
        "train_dataset = Dataset(directory, task, plane,\n",
        "                         train=True, transform=augmentor)\n",
        "valid_dataset = Dataset(\n",
        "      directory, task, plane, train=False, transform = None)\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_dataset, batch_size=10, shuffle=True, num_workers=2, drop_last=False)\n",
        "valid_loader = torch.utils.data.DataLoader(\n",
        "    valid_dataset, batch_size=10, shuffle=False, num_workers=2, drop_last=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QiJu89o8phOl"
      },
      "source": [
        "##Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V3K5DBz45L6f",
        "outputId": "6d0b847a-328e-4d69-b710-7d4cf3ef87f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting epoch 1/50\n",
            "Starting training phase\n",
            "Training batch 1/113\n",
            "Training batch 2/113\n",
            "Training batch 3/113\n",
            "Training batch 4/113\n",
            "Training batch 5/113\n",
            "Training batch 6/113\n",
            "Training batch 7/113\n",
            "Training batch 8/113\n",
            "Training batch 9/113\n",
            "Training batch 10/113\n",
            "Training batch 11/113\n",
            "Training batch 12/113\n",
            "Training batch 13/113\n",
            "Training batch 14/113\n",
            "Training batch 15/113\n",
            "Training batch 16/113\n",
            "Training batch 17/113\n",
            "Training batch 18/113\n",
            "Training batch 19/113\n",
            "Training batch 20/113\n",
            "Training batch 21/113\n",
            "Training batch 22/113\n",
            "Training batch 23/113\n",
            "Training batch 24/113\n",
            "Training batch 25/113\n",
            "Training batch 26/113\n",
            "Training batch 27/113\n",
            "Training batch 28/113\n",
            "Training batch 29/113\n",
            "Training batch 30/113\n",
            "Training batch 31/113\n",
            "Training batch 32/113\n",
            "Training batch 33/113\n",
            "Training batch 34/113\n",
            "Training batch 35/113\n",
            "Training batch 36/113\n",
            "Training batch 37/113\n",
            "Training batch 38/113\n",
            "Training batch 39/113\n",
            "Training batch 40/113\n",
            "Training batch 41/113\n",
            "Training batch 42/113\n",
            "Training batch 43/113\n",
            "Training batch 44/113\n",
            "Training batch 45/113\n",
            "Training batch 46/113\n",
            "Training batch 47/113\n",
            "Training batch 48/113\n",
            "Training batch 49/113\n",
            "Training batch 50/113\n",
            "Training batch 51/113\n",
            "Training batch 52/113\n",
            "Training batch 53/113\n",
            "Training batch 54/113\n",
            "Training batch 55/113\n",
            "Training batch 56/113\n",
            "Training batch 57/113\n",
            "Training batch 58/113\n",
            "Training batch 59/113\n",
            "Training batch 60/113\n",
            "Training batch 61/113\n",
            "Training batch 62/113\n",
            "Training batch 63/113\n",
            "Training batch 64/113\n",
            "Training batch 65/113\n",
            "Training batch 66/113\n",
            "Training batch 67/113\n",
            "Training batch 68/113\n",
            "Training batch 69/113\n",
            "Training batch 70/113\n",
            "Training batch 71/113\n",
            "Training batch 72/113\n",
            "Training batch 73/113\n",
            "Training batch 74/113\n",
            "Training batch 75/113\n",
            "Training batch 76/113\n",
            "Training batch 77/113\n",
            "Training batch 78/113\n",
            "Training batch 79/113\n",
            "Training batch 80/113\n",
            "Training batch 81/113\n",
            "Training batch 82/113\n",
            "Training batch 83/113\n",
            "Training batch 84/113\n",
            "Training batch 85/113\n",
            "Training batch 86/113\n",
            "Training batch 87/113\n",
            "Training batch 88/113\n",
            "Training batch 89/113\n",
            "Training batch 90/113\n",
            "Training batch 91/113\n",
            "Training batch 92/113\n",
            "Training batch 93/113\n",
            "Training batch 94/113\n",
            "Training batch 95/113\n",
            "Training batch 96/113\n",
            "Training batch 97/113\n",
            "Training batch 98/113\n",
            "Training batch 99/113\n",
            "Training batch 100/113\n",
            "Training batch 101/113\n",
            "Training batch 102/113\n",
            "Training batch 103/113\n",
            "Training batch 104/113\n",
            "Training batch 105/113\n",
            "Training batch 106/113\n",
            "Training batch 107/113\n",
            "Training batch 108/113\n",
            "Training batch 109/113\n",
            "Training batch 110/113\n",
            "Training batch 111/113\n",
            "Training batch 112/113\n",
            "Training batch 113/113\n",
            "Starting validation phase\n",
            "Validation batch 1/12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation batch 2/12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation batch 3/12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation batch 4/12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation batch 5/12\n",
            "Validation batch 6/12\n",
            "Validation batch 7/12\n",
            "Validation batch 8/12\n",
            "Validation batch 9/12\n",
            "Validation batch 10/12\n",
            "Validation batch 11/12\n",
            "Validation batch 12/12\n",
            "epoch : 0 | train loss : 1.2124 | train auc 0.6044 | val loss 22.731 | val auc 0.6706 \n",
            "------------------------------\n",
            "Starting epoch 2/50\n",
            "Starting training phase\n",
            "Training batch 1/113\n",
            "Training batch 2/113\n",
            "Training batch 3/113\n",
            "Training batch 4/113\n",
            "Training batch 5/113\n",
            "Training batch 6/113\n",
            "Training batch 7/113\n",
            "Training batch 8/113\n",
            "Training batch 9/113\n",
            "Training batch 10/113\n",
            "Training batch 11/113\n",
            "Training batch 12/113\n",
            "Training batch 13/113\n",
            "Training batch 14/113\n",
            "Training batch 15/113\n",
            "Training batch 16/113\n",
            "Training batch 17/113\n",
            "Training batch 18/113\n",
            "Training batch 19/113\n",
            "Training batch 20/113\n",
            "Training batch 21/113\n",
            "Training batch 22/113\n",
            "Training batch 23/113\n",
            "Training batch 24/113\n",
            "Training batch 25/113\n",
            "Training batch 26/113\n",
            "Training batch 27/113\n",
            "Training batch 28/113\n",
            "Training batch 29/113\n",
            "Training batch 30/113\n",
            "Training batch 31/113\n",
            "Training batch 32/113\n",
            "Training batch 33/113\n",
            "Training batch 34/113\n",
            "Training batch 35/113\n",
            "Training batch 36/113\n",
            "Training batch 37/113\n",
            "Training batch 38/113\n",
            "Training batch 39/113\n",
            "Training batch 40/113\n",
            "Training batch 41/113\n",
            "Training batch 42/113\n",
            "Training batch 43/113\n",
            "Training batch 44/113\n",
            "Training batch 45/113\n",
            "Training batch 46/113\n",
            "Training batch 47/113\n",
            "Training batch 48/113\n",
            "Training batch 49/113\n",
            "Training batch 50/113\n",
            "Training batch 51/113\n",
            "Training batch 52/113\n",
            "Training batch 53/113\n",
            "Training batch 54/113\n",
            "Training batch 55/113\n",
            "Training batch 56/113\n",
            "Training batch 57/113\n",
            "Training batch 58/113\n",
            "Training batch 59/113\n",
            "Training batch 60/113\n",
            "Training batch 61/113\n",
            "Training batch 62/113\n",
            "Training batch 63/113\n",
            "Training batch 64/113\n",
            "Training batch 65/113\n",
            "Training batch 66/113\n",
            "Training batch 67/113\n",
            "Training batch 68/113\n",
            "Training batch 69/113\n",
            "Training batch 70/113\n",
            "Training batch 71/113\n",
            "Training batch 72/113\n",
            "Training batch 73/113\n",
            "Training batch 74/113\n",
            "Training batch 75/113\n",
            "Training batch 76/113\n",
            "Training batch 77/113\n",
            "Training batch 78/113\n",
            "Training batch 79/113\n",
            "Training batch 80/113\n",
            "Training batch 81/113\n",
            "Training batch 82/113\n",
            "Training batch 83/113\n",
            "Training batch 84/113\n",
            "Training batch 85/113\n",
            "Training batch 86/113\n",
            "Training batch 87/113\n",
            "Training batch 88/113\n",
            "Training batch 89/113\n",
            "Training batch 90/113\n",
            "Training batch 91/113\n",
            "Training batch 92/113\n",
            "Training batch 93/113\n",
            "Training batch 94/113\n",
            "Training batch 95/113\n",
            "Training batch 96/113\n",
            "Training batch 97/113\n",
            "Training batch 98/113\n",
            "Training batch 99/113\n",
            "Training batch 100/113\n",
            "Training batch 101/113\n",
            "Training batch 102/113\n",
            "Training batch 103/113\n",
            "Training batch 104/113\n",
            "Training batch 105/113\n",
            "Training batch 106/113\n",
            "Training batch 107/113\n",
            "Training batch 108/113\n",
            "Training batch 109/113\n",
            "Training batch 110/113\n",
            "Training batch 111/113\n",
            "Training batch 112/113\n",
            "Training batch 113/113\n",
            "Starting validation phase\n",
            "Validation batch 1/12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation batch 2/12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation batch 3/12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation batch 4/12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation batch 5/12\n",
            "Validation batch 6/12\n",
            "Validation batch 7/12\n",
            "Validation batch 8/12\n",
            "Validation batch 9/12\n",
            "Validation batch 10/12\n",
            "Validation batch 11/12\n",
            "Validation batch 12/12\n",
            "epoch : 1 | train loss : 1.0014 | train auc 0.7202 | val loss 32.2786 | val auc 0.6888 \n",
            "------------------------------\n",
            "Starting epoch 3/50\n",
            "Starting training phase\n",
            "Training batch 1/113\n",
            "Training batch 2/113\n",
            "Training batch 3/113\n",
            "Training batch 4/113\n",
            "Training batch 5/113\n",
            "Training batch 6/113\n",
            "Training batch 7/113\n",
            "Training batch 8/113\n",
            "Training batch 9/113\n",
            "Training batch 10/113\n",
            "Training batch 11/113\n",
            "Training batch 12/113\n",
            "Training batch 13/113\n",
            "Training batch 14/113\n",
            "Training batch 15/113\n",
            "Training batch 16/113\n",
            "Training batch 17/113\n",
            "Training batch 18/113\n",
            "Training batch 19/113\n",
            "Training batch 20/113\n",
            "Training batch 21/113\n",
            "Training batch 22/113\n",
            "Training batch 23/113\n",
            "Training batch 24/113\n",
            "Training batch 25/113\n",
            "Training batch 26/113\n",
            "Training batch 27/113\n",
            "Training batch 28/113\n",
            "Training batch 29/113\n",
            "Training batch 30/113\n",
            "Training batch 31/113\n",
            "Training batch 32/113\n",
            "Training batch 33/113\n",
            "Training batch 34/113\n",
            "Training batch 35/113\n",
            "Training batch 36/113\n",
            "Training batch 37/113\n",
            "Training batch 38/113\n",
            "Training batch 39/113\n",
            "Training batch 40/113\n",
            "Training batch 41/113\n",
            "Training batch 42/113\n",
            "Training batch 43/113\n",
            "Training batch 44/113\n",
            "Training batch 45/113\n",
            "Training batch 46/113\n",
            "Training batch 47/113\n",
            "Training batch 48/113\n",
            "Training batch 49/113\n",
            "Training batch 50/113\n",
            "Training batch 51/113\n",
            "Training batch 52/113\n",
            "Training batch 53/113\n",
            "Training batch 54/113\n",
            "Training batch 55/113\n",
            "Training batch 56/113\n",
            "Training batch 57/113\n",
            "Training batch 58/113\n",
            "Training batch 59/113\n",
            "Training batch 60/113\n",
            "Training batch 61/113\n",
            "Training batch 62/113\n",
            "Training batch 63/113\n",
            "Training batch 64/113\n",
            "Training batch 65/113\n",
            "Training batch 66/113\n",
            "Training batch 67/113\n",
            "Training batch 68/113\n",
            "Training batch 69/113\n",
            "Training batch 70/113\n",
            "Training batch 71/113\n",
            "Training batch 72/113\n",
            "Training batch 73/113\n",
            "Training batch 74/113\n",
            "Training batch 75/113\n",
            "Training batch 76/113\n",
            "Training batch 77/113\n",
            "Training batch 78/113\n",
            "Training batch 79/113\n",
            "Training batch 80/113\n",
            "Training batch 81/113\n",
            "Training batch 82/113\n",
            "Training batch 83/113\n",
            "Training batch 84/113\n",
            "Training batch 85/113\n",
            "Training batch 86/113\n",
            "Training batch 87/113\n",
            "Training batch 88/113\n",
            "Training batch 89/113\n",
            "Training batch 90/113\n",
            "Training batch 91/113\n",
            "Training batch 92/113\n",
            "Training batch 93/113\n",
            "Training batch 94/113\n",
            "Training batch 95/113\n",
            "Training batch 96/113\n",
            "Training batch 97/113\n",
            "Training batch 98/113\n",
            "Training batch 99/113\n",
            "Training batch 100/113\n",
            "Training batch 101/113\n",
            "Training batch 102/113\n",
            "Training batch 103/113\n",
            "Training batch 104/113\n",
            "Training batch 105/113\n",
            "Training batch 106/113\n",
            "Training batch 107/113\n",
            "Training batch 108/113\n",
            "Training batch 109/113\n",
            "Training batch 110/113\n",
            "Training batch 111/113\n",
            "Training batch 112/113\n",
            "Training batch 113/113\n",
            "Starting validation phase\n",
            "Validation batch 1/12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation batch 2/12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation batch 3/12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation batch 4/12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation batch 5/12\n",
            "Validation batch 6/12\n",
            "Validation batch 7/12\n",
            "Validation batch 8/12\n",
            "Validation batch 9/12\n",
            "Validation batch 10/12\n",
            "Validation batch 11/12\n",
            "Validation batch 12/12\n",
            "epoch : 2 | train loss : 0.9387 | train auc 0.7767 | val loss 27.1689 | val auc 0.6765 \n",
            "------------------------------\n",
            "Starting epoch 4/50\n",
            "Starting training phase\n",
            "Training batch 1/113\n",
            "Training batch 2/113\n",
            "Training batch 3/113\n",
            "Training batch 4/113\n",
            "Training batch 5/113\n",
            "Training batch 6/113\n",
            "Training batch 7/113\n",
            "Training batch 8/113\n",
            "Training batch 9/113\n",
            "Training batch 10/113\n",
            "Training batch 11/113\n",
            "Training batch 12/113\n",
            "Training batch 13/113\n",
            "Training batch 14/113\n",
            "Training batch 15/113\n",
            "Training batch 16/113\n",
            "Training batch 17/113\n",
            "Training batch 18/113\n",
            "Training batch 19/113\n",
            "Training batch 20/113\n",
            "Training batch 21/113\n",
            "Training batch 22/113\n",
            "Training batch 23/113\n",
            "Training batch 24/113\n",
            "Training batch 25/113\n",
            "Training batch 26/113\n",
            "Training batch 27/113\n",
            "Training batch 28/113\n",
            "Training batch 29/113\n",
            "Training batch 30/113\n",
            "Training batch 31/113\n",
            "Training batch 32/113\n",
            "Training batch 33/113\n",
            "Training batch 34/113\n",
            "Training batch 35/113\n",
            "Training batch 36/113\n",
            "Training batch 37/113\n",
            "Training batch 38/113\n",
            "Training batch 39/113\n",
            "Training batch 40/113\n",
            "Training batch 41/113\n",
            "Training batch 42/113\n",
            "Training batch 43/113\n",
            "Training batch 44/113\n",
            "Training batch 45/113\n",
            "Training batch 46/113\n",
            "Training batch 47/113\n",
            "Training batch 48/113\n",
            "Training batch 49/113\n",
            "Training batch 50/113\n",
            "Training batch 51/113\n",
            "Training batch 52/113\n",
            "Training batch 53/113\n",
            "Training batch 54/113\n",
            "Training batch 55/113\n",
            "Training batch 56/113\n",
            "Training batch 57/113\n",
            "Training batch 58/113\n",
            "Training batch 59/113\n",
            "Training batch 60/113\n",
            "Training batch 61/113\n"
          ]
        }
      ],
      "source": [
        "import logging\n",
        "\n",
        "# Configure logging\n",
        "# logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s') # Removed logging configuration\n",
        "\n",
        "early_trigger = 10 #if the validation AUC hasn't increased in ten epochs, stop the training\n",
        "early_stop = 0 #counter for the number of iterations where there has been no increase in validation AUC\n",
        "best_val_auc = 0\n",
        "#for loop for each epoch\n",
        "for epoch in range(num_epochs):\n",
        "      print(f\"Starting epoch {epoch+1}/{num_epochs}\")\n",
        "      #get learning rate\n",
        "      current_lr = lr\n",
        "\n",
        "      y_preds = []\n",
        "      y_trues = []\n",
        "      losses = []\n",
        "      _ = model.train()\n",
        "      print(\"Starting training phase\") # Changed to print\n",
        "      #loop through each MRI in the training set\n",
        "      for i, (image, label, weight) in enumerate(train_loader):\n",
        "          print(f\"Training batch {i+1}/{len(train_loader)}\") # Changed to print\n",
        "          optimizer.zero_grad()\n",
        "\n",
        "          #load all data onto the GPU\n",
        "          if torch.cuda.is_available():\n",
        "              image = image.cuda()\n",
        "              label = label.cuda()\n",
        "              weight = weight.cuda()\n",
        "\n",
        "          #pass the MRI through the model\n",
        "          prediction = model.forward(image.float())\n",
        "\n",
        "          #calculate the loss\n",
        "          loss = torch.nn.BCEWithLogitsLoss(weight=weight)(prediction, label)\n",
        "          loss.backward() #back propagation\n",
        "          optimizer.step()\n",
        "\n",
        "          loss_value = loss.item()\n",
        "          losses.append(loss_value)\n",
        "\n",
        "          probas = torch.sigmoid(prediction) #convert output of model (logits) to a value between zero and one. This can be interpretted as a probability\n",
        "\n",
        "          y_trues.extend(label.cpu().tolist())\n",
        "          y_preds.extend(probas.cpu().tolist())\n",
        "\n",
        "          try:\n",
        "              auc = metrics.roc_auc_score(y_trues, y_preds)\n",
        "          except:\n",
        "              auc = 0.5\n",
        "\n",
        "          train_loss = np.round(np.mean(losses), 4)\n",
        "          train_auc = np.round(auc, 4)\n",
        "\n",
        "      #evaluate the model on the validation data after each epoch\n",
        "      _ = model.eval()\n",
        "      y_trues = []\n",
        "      y_preds = []\n",
        "      losses = []\n",
        "      print(\"Starting validation phase\") # Changed to print\n",
        "      for i, (image, label, weight) in enumerate(valid_loader):\n",
        "        print(f\"Validation batch {i+1}/{len(valid_loader)}\") # Changed to print\n",
        "        if torch.cuda.is_available():\n",
        "            image = image.cuda()\n",
        "            label = label.cuda()\n",
        "            weight = weight.cuda()\n",
        "\n",
        "\n",
        "        prediction = model.forward(image.float())\n",
        "\n",
        "        loss = torch.nn.BCEWithLogitsLoss(weight=weight)(prediction, label)\n",
        "\n",
        "        loss_value = loss.item()\n",
        "        losses.append(loss_value)\n",
        "\n",
        "        probas = torch.sigmoid(prediction)\n",
        "\n",
        "        y_trues.extend(label.cpu().tolist())\n",
        "        y_preds.extend(probas.cpu().tolist())\n",
        "\n",
        "        try:\n",
        "            auc = metrics.roc_auc_score(y_trues, y_preds)\n",
        "        except:\n",
        "            auc = 0.5\n",
        "\n",
        "        val_loss = np.round(np.mean(losses), 4)\n",
        "        val_auc = np.round(auc, 4)\n",
        "\n",
        "      if val_auc > best_val_auc:\n",
        "        best_val_auc = val_auc\n",
        "        early_stop=0\n",
        "      else:\n",
        "        early_stop+= 1\n",
        "\n",
        "      if early_stop == early_trigger:\n",
        "        print('Early stopping after {} epochs'.format(epoch))\n",
        "        sys.exit()\n",
        "      scheduler.step(val_loss)\n",
        "\n",
        "      print(\"epoch : {0} | train loss : {1} | train auc {2} | val loss {3} | val auc {4} \".format(\n",
        "          epoch, train_loss, train_auc, val_loss, val_auc))\n",
        "\n",
        "\n",
        "      print('-' * 30)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V6E1",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}