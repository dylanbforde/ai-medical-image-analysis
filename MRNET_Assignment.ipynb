{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dylanbforde/ai-medical-image-analysis/blob/main/MRNET_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "54525192",
      "metadata": {
        "id": "54525192"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a3f2a2a5",
      "metadata": {
        "id": "a3f2a2a5"
      },
      "outputs": [],
      "source": [
        "!pip install torchsample\n",
        "!pip install visdom\n",
        "!pip install nibabel\n",
        "!pip install h5py\n",
        "!pip install tensorboardX\n",
        "!pip install optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0c869f30",
      "metadata": {
        "id": "0c869f30"
      },
      "outputs": [],
      "source": [
        "import optuna\n",
        "import torch.optim as optim\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models\n",
        "import numpy as np\n",
        "import os\n",
        "import sys\n",
        "import pickle\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data as data\n",
        "import pandas as pd\n",
        "from torch.autograd import Variable\n",
        "from torchvision import transforms\n",
        "from tensorboardX import SummaryWriter\n",
        "import math\n",
        "from sklearn import metrics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8fd959e3",
      "metadata": {
        "id": "8fd959e3"
      },
      "outputs": [],
      "source": [
        "# Modify the Net class to use R2Plus1D_18\n",
        "import torchvision.models.video as video_models\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # Load the pretrained R2Plus1D_18 model\n",
        "        self.pretrained_model = video_models.r2plus1d_18(pretrained=True)\n",
        "\n",
        "        # Modify the last fully connected layer to output (1)\n",
        "        # The in_features for R2Plus1D_18's fc layer is 512\n",
        "        self.classifer = nn.Linear(self.pretrained_model.fc.in_features, 1)\n",
        "\n",
        "        # Add a Dropout layer after the classifier\n",
        "        self.dropout = nn.Dropout(0.5) # Experiment with a dropout rate of 0.5\n",
        "\n",
        "        # Remove the original fully connected layer from the pretrained model\n",
        "        self.pretrained_model.fc = nn.Identity()\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        # input size of x (batch_size, s, 3, 256, 256) where s is the number of slices in one MRI\n",
        "        # R2Plus1D_18 expects input in (batch_size, channels, time, height, width) format\n",
        "        # Permute the input to match the expected format (batch_size, 3, s, 256, 256)\n",
        "        x = x.permute(0, 2, 1, 3, 4) # output size (batch_size, 3, num_slices, 256, 256)\n",
        "\n",
        "        x = self.pretrained_model(x) # output size (batch_size, 512)\n",
        "\n",
        "        # Pass through classifier\n",
        "        output = self.classifer(x) # output size (batch_size, 1)\n",
        "\n",
        "        # Apply dropout\n",
        "        output = self.dropout(output)\n",
        "\n",
        "        return output\n",
        "\n",
        "# Re-initialize the model with the new architecture\n",
        "model = Net()\n",
        "if torch.cuda.is_available():\n",
        "    model = model.cuda()\n",
        "\n",
        "# Keep the existing optimizer, scheduler, and data loaders\n",
        "# (These are defined in the previous cells and will be used in the training loop)\n",
        "\n",
        "print(\"Model architecture modified to use R2Plus1D_18 model.\")\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "594ed229",
      "metadata": {
        "id": "594ed229"
      },
      "outputs": [],
      "source": [
        "class Dataset(data.Dataset):\n",
        "    def __init__(self, root_dir, task, plane, train=False, transform=None):\n",
        "        super().__init__()\n",
        "        self.task = task\n",
        "        self.plane = plane\n",
        "        self.root_dir = root_dir\n",
        "        self.train=train\n",
        "        if self.train == True:\n",
        "            self.folder_path = self.root_dir + 'train/{0}/'.format(plane)\n",
        "            self.records = pd.read_csv(\n",
        "                self.root_dir + 'train-{0}.csv'.format(task), header=None, names=['id', 'label'])\n",
        "        else:\n",
        "            self.folder_path = self.root_dir + 'valid/{0}/'.format(plane)\n",
        "\n",
        "            self.records = pd.read_csv(\n",
        "                self.root_dir + 'valid-{0}.csv'.format(task), header=None, names=['id', 'label'])\n",
        "\n",
        "        self.records['id'] = self.records['id'].map(\n",
        "            lambda i: '0' * (4 - len(str(i))) + str(i))\n",
        "        self.paths = [self.folder_path + filename +\n",
        "                      '.npy' for filename in self.records['id'].tolist()]\n",
        "        self.labels = self.records['label'].tolist()\n",
        "\n",
        "        self.transform = transform\n",
        "\n",
        "        pos = np.sum(self.labels)\n",
        "        neg = len(self.labels) - pos\n",
        "        self.weights = [1, neg / pos]\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.paths)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        array = np.load(self.paths[index])\n",
        "\n",
        "        label = self.labels[index]\n",
        "        label = torch.FloatTensor([label])\n",
        "\n",
        "        if self.transform:\n",
        "          transformed_slices = []\n",
        "          for i in array:\n",
        "            # Apply transform to each slice\n",
        "            transformed_slice = self.transform(i)\n",
        "            transformed_slice = transformed_slice.repeat(3, 1, 1)\n",
        "            transformed_slices.append(transformed_slice)\n",
        "          array = torch.stack(transformed_slices)\n",
        "        else:\n",
        "          array = torch.from_numpy(array).float()\n",
        "          array = array.unsqueeze(1)\n",
        "          array = array.repeat(1, 3, 1, 1)\n",
        "\n",
        "        array = array.float()\n",
        "\n",
        "        if label.item() == 1:\n",
        "            weight = np.array([self.weights[1]])\n",
        "            weight = torch.FloatTensor(weight)\n",
        "        else:\n",
        "            weight = np.array([self.weights[0]])\n",
        "            weight = torch.FloatTensor(weight)\n",
        "\n",
        "        if array.shape[0] < 32:\n",
        "            zeros = torch.zeros((32 - array.shape[0], 3, 256, 256))\n",
        "            array = torch.cat((array, zeros), 0)\n",
        "\n",
        "        elif array.shape[0] > 32:\n",
        "            array = array[:32, :, :, :]\n",
        "\n",
        "        return array, label, weight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d5bcb6ca",
      "metadata": {
        "id": "d5bcb6ca"
      },
      "outputs": [],
      "source": [
        "def objective(trial):\n",
        "    # Define the hyperparameters to tune\n",
        "    lr = trial.suggest_float('lr', 1e-6, 1e-4, log=True)\n",
        "    weight_decay = trial.suggest_float('weight_decay', 1e-5, 1e-3, log=True)\n",
        "    batch_size = trial.suggest_categorical('batch_size', [8, 16, 32]) # Example batch sizes\n",
        "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.6) # Tune dropout rate\n",
        "    trial_number = trial.number\n",
        "\n",
        "    # --- Model Initialization ---\n",
        "    model = Net()\n",
        "    # Update the dropout rate in the model with the suggested value from Optuna\n",
        "    model.dropout.p = dropout_rate\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        model = model.cuda()\n",
        "\n",
        "    # Change the optimizer to AdamW\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "        optimizer, patience=2, factor=.3, threshold=1e-4, verbose=False) # Reduced patience for tuning\n",
        "\n",
        "    # --- Data Loading ---\n",
        "    directory = \"/content/drive/Shared drives/MRNet Group Assignment/MRI Data/\"\n",
        "    task = 'acl'\n",
        "    plane = 'sagittal'\n",
        "\n",
        "    augmentor = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.RandomRotation(25),\n",
        "        transforms.RandomAffine(degrees=0, translate=(0.11, 0.11)),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.GaussianBlur(kernel_size=3, sigma=(0.1, 2.0)) # Added Gaussian Blur\n",
        "    ])\n",
        "\n",
        "    train_dataset = Dataset(directory, task, plane, train=True, transform=augmentor)\n",
        "    valid_dataset = Dataset(directory, task, plane, train=False, transform = None)\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        train_dataset, batch_size=batch_size, shuffle=True, num_workers=2, drop_last=False)\n",
        "    valid_loader = torch.utils.data.DataLoader(\n",
        "        valid_dataset, batch_size=batch_size, shuffle=False, num_workers=2, drop_last=False)\n",
        "\n",
        "\n",
        "    # --- Training Loop (Shortened for Tuning) ---\n",
        "    num_tuning_epochs = 5 # Reduced number of epochs for faster tuning trials\n",
        "    best_val_auc = 0\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "\n",
        "\n",
        "    for epoch in range(num_tuning_epochs):\n",
        "        model.train()\n",
        "        y_preds = []\n",
        "        y_trues = []\n",
        "        running_loss = 0.0\n",
        "        for i, (image, label, weight) in enumerate(train_loader):\n",
        "            optimizer.zero_grad()\n",
        "            if torch.cuda.is_available():\n",
        "                image = image.cuda()\n",
        "                label = label.cuda()\n",
        "                weight = weight.cuda()\n",
        "\n",
        "            prediction = model.forward(image.float())\n",
        "            loss = torch.nn.BCEWithLogitsLoss(weight=weight)(prediction, label)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "            probas = torch.sigmoid(prediction)\n",
        "            y_trues.extend(label.cpu().tolist())\n",
        "            y_preds.extend(probas.cpu().tolist())\n",
        "        train_losses.append(running_loss / len(train_loader))\n",
        "\n",
        "        # Evaluate on validation set\n",
        "        model.eval()\n",
        "        y_trues_val = []\n",
        "        y_preds_val = []\n",
        "        running_val_loss = 0.0\n",
        "        with torch.no_grad():\n",
        "            for i, (image, label, weight) in enumerate(valid_loader):\n",
        "                if torch.cuda.is_available():\n",
        "                    image = image.cuda()\n",
        "                    label = label.cuda()\n",
        "                    weight = weight.cuda()\n",
        "\n",
        "                prediction = model.forward(image.float())\n",
        "                loss = torch.nn.BCEWithLogitsLoss(weight=weight)(prediction, label)\n",
        "                running_val_loss += loss.item()\n",
        "                probas = torch.sigmoid(prediction)\n",
        "                y_trues_val.extend(label.cpu().tolist())\n",
        "                y_preds_val.extend(probas.cpu().tolist())\n",
        "        val_losses.append(running_val_loss / len(valid_loader))\n",
        "\n",
        "        try:\n",
        "            val_auc = metrics.roc_auc_score(y_trues_val, y_preds_val)\n",
        "        except:\n",
        "            val_auc = 0.5 # Handle case with only one class\n",
        "\n",
        "        # Report intermediate objective value to Optuna\n",
        "        trial.report(val_auc, epoch)\n",
        "\n",
        "        # Handle pruning based on the intermediate value\n",
        "        if trial.should_prune():\n",
        "            raise optuna.exceptions.TrialPruned()\n",
        "\n",
        "        if val_auc > best_val_auc:\n",
        "            best_val_auc = val_auc\n",
        "\n",
        "    # Store training and validation losses in trial user attributes\n",
        "    trial.set_user_attr(\"train_losses\", train_losses)\n",
        "    trial.set_user_attr(\"val_losses\", val_losses)\n",
        "\n",
        "    model_save_path = f'/content/drive/MyDrive/my_acl_sagittal_model_trial_{trial_number}.pth'\n",
        "\n",
        "    # Save the model's state dictionary\n",
        "    torch.save(model.state_dict(), model_save_path)\n",
        "\n",
        "    return best_val_auc # Return the best validation AUC for this trial\n",
        "\n",
        "# --- Run the Optuna study ---\n",
        "# Specify the number of trials to run. Keep this small initially to manage computation cost.\n",
        "n_trials = 10 # You can increase this number for a more extensive search, however my compute credits are low\n",
        "\n",
        "print(f\"Running Optuna study for {n_trials} trials...\")\n",
        "\n",
        "# Create a study object and specify the direction (maximize validation AUC)\n",
        "study = optuna.create_study(direction='maximize')\n",
        "\n",
        "# Run the optimization study\n",
        "study.optimize(objective, n_trials=n_trials)\n",
        "\n",
        "print(\"\\nOptuna study finished.\")\n",
        "\n",
        "# Print the best trial's hyperparameters and value\n",
        "print(\"Best trial:\")\n",
        "print(f\"  Value: {study.best_trial.value}\")\n",
        "print(\"  Params: \")\n",
        "for key, value in study.best_trial.params.items():\n",
        "    print(f\"    {key}: {value}\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0d47749f"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "print(\"Visualizing training and validation losses for each trial...\")\n",
        "\n",
        "for trial in study.trials:\n",
        "    trial_number = trial.number\n",
        "    train_losses = trial.user_attrs.get(\"train_losses\")\n",
        "    val_losses = trial.user_attrs.get(\"val_losses\")\n",
        "\n",
        "    if train_losses is not None and val_losses is not None:\n",
        "        epochs = range(1, len(train_losses) + 1)\n",
        "\n",
        "        plt.figure()\n",
        "        plt.plot(epochs, train_losses, label=f'Trial {trial_number} Training Loss')\n",
        "        plt.plot(epochs, val_losses, label=f'Trial {trial_number} Validation Loss')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.title(f'Training and Validation Loss for Trial {trial_number}')\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "        plt.show()\n",
        "    else:\n",
        "        print(f\"Loss data not found for Trial {trial_number}\")\n",
        "\n",
        "print(\"Visualization complete.\")"
      ],
      "id": "0d47749f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Set the model to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "y_trues = []\n",
        "y_preds = []\n",
        "examples = []\n",
        "\n",
        "# Disable gradient calculation for evaluation\n",
        "with torch.no_grad():\n",
        "    for i, (image, label, weight) in enumerate(valid_loader):\n",
        "        if torch.cuda.is_available():\n",
        "            # Keep image on GPU for prediction, but will move to CPU for display later\n",
        "            image_gpu = image.cuda()\n",
        "        else:\n",
        "            image_gpu = image\n",
        "\n",
        "        prediction = model.forward(image_gpu.float())\n",
        "        probas = torch.sigmoid(prediction)\n",
        "\n",
        "        y_trues.extend(label.cpu().tolist())\n",
        "        y_preds.extend(probas.cpu().tolist())\n",
        "\n",
        "        # Store examples with predictions, true labels, and the image data (on CPU)\n",
        "        for j in range(image.size(0)):\n",
        "            examples.append({\n",
        "                'predicted_proba': probas[j].item(),\n",
        "                'true_label': label[j].item(),\n",
        "                'image': image[j].cpu().numpy() # Store image data on CPU\n",
        "            })\n",
        "\n",
        "# Display some examples\n",
        "print(\"Examples of Classifications:\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "# Display a few correct classifications\n",
        "print(\"Correct Classifications:\")\n",
        "correct_examples = [ex for ex in examples if (ex['predicted_proba'] > 0.5 and ex['true_label'] == 1.0) or (ex['predicted_proba'] <= 0.5 and ex['true_label'] == 0.0)]\n",
        "for i, ex in enumerate(correct_examples[:3]): # Display up to 3 correct examples\n",
        "    print(f\"Example {i+1}: Predicted Probability = {ex['predicted_proba']:.4f}, True Label = {int(ex['true_label'])}\")\n",
        "    img_data = ex['image'] # Shape is (num_slices, channels, height, width)\n",
        "    num_slices = img_data.shape[0]\n",
        "    # Display a few slices\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "    slices_to_show = [0, 2, 4] # Display first, third, and fifth slices\n",
        "    for k, slice_idx in enumerate(slices_to_show):\n",
        "        if slice_idx < num_slices:\n",
        "            # Assuming grayscale image with 3 repeated channels, take one channel\n",
        "            axes[k].imshow(img_data[slice_idx, 0, :, :], cmap='gray')\n",
        "            axes[k].set_title(f\"Slice {slice_idx}\")\n",
        "            axes[k].axis('off')\n",
        "    plt.show()\n",
        "    print(\"-\" * 30)\n",
        "\n",
        "\n",
        "# Display a few incorrect classifications\n",
        "print(\"Incorrect Classifications:\")\n",
        "incorrect_examples = [ex for ex in examples if (ex['predicted_proba'] > 0.5 and ex['true_label'] == 0.0) or (ex['predicted_proba'] <= 0.5 and ex['true_label'] == 1.0)]\n",
        "for i, ex in enumerate(incorrect_examples[:3]): # Display up to 3 incorrect examples\n",
        "    print(f\"Example {i+1}: Predicted Probability = {ex['predicted_proba']:.4f}, True Label = {int(ex['true_label'])}\")\n",
        "    img_data = ex['image'] # Shape is (num_slices, channels, height, width)\n",
        "    num_slices = img_data.shape[0]\n",
        "    # Display a few slices\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "    slices_to_show = [0, 2, 4] # Display first, third, and fifth slices\n",
        "    for k, slice_idx in enumerate(slices_to_show):\n",
        "         if slice_idx < num_slices:\n",
        "            axes[k].imshow(img_data[slice_idx, 0, :, :], cmap='gray')\n",
        "            axes[k].set_title(f\"Slice {slice_idx}\")\n",
        "            axes[k].axis('off')\n",
        "    plt.show()\n",
        "    print(\"-\" * 30)"
      ],
      "metadata": {
        "id": "V9ucZ7NV4ocm"
      },
      "id": "V9ucZ7NV4ocm",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}